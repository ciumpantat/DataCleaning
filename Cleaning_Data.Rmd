---
title: "Cleaning_Assignment"
author: "Andi Musrah"
date: "April 2, 2016"
output: html_document
---

## Getting-and-Cleanning-data

> Repo for the Project from the Getting and Cleanning Data course Overview

> This project intends to demonstrate the importance and the ability to collect, work with and clean a data set. The goal is to prepare a tidy data that can be use for later analysis. The data was collected from the web site that can be found in the following address https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip Project Summary Develop a R script called run_analysis.R that does the following.

> Merges the training and the test sets to create one data set.
Extracts only the measurements on the mean and standard deviation for each measurement.
Uses descriptive activity names to name the activities in the data set
Appropriately labels the data set with descriptive variable names.
finally creates a second independent tidy data set with the average of each variable for each activity and each subject.
Also in the repo should present the following documentation

> The R script run_analysis containing all the information
A link to a Github repository with your script for performing the analysis
A code book that describes the variables, the data, and any transformations or work that was performed to clean up the data called CodeBook.md.
A README.md in the repo with your scripts. This repo explains how all of the scripts work and how they are connected.

### Load the tool packages

The libraries used in this operation are `data.table` and `dplyr`. We prefer `data.table` as it is efficient in handling large data as tables `dplyr` is used to aggregate variables to create the tidy data.

```{r}
setwd("~/Documents/DataCleaning")
```

```{r}
library(data.table)
library(dplyr)
```

### Read Supporting Metadata
The supporting metadata in this data are the name of the features and the name of the activities. They are loaded into variables `featureNames` and `activityLabels`.

```{r}
featureNames <- read.table("UCI HAR Dataset/features.txt")
activityLabels <- read.table("UCI HAR Dataset/activity_labels.txt", header = FALSE)
```

## Format training and test data sets
Both training and test data sets are split up into subject, activity and features. They are present in three different files.

### Read training data
```{r}
subjectTrain <- read.table("UCI HAR Dataset/train/subject_train.txt", header = FALSE)
activityTrain <- read.table("UCI HAR Dataset/train/y_train.txt", header = FALSE)
featuresTrain <- read.table("UCI HAR Dataset/train/X_train.txt", header = FALSE)
```

### Read test data
```{r}
subjectTest <- read.table("UCI HAR Dataset/test/subject_test.txt", header = FALSE)
activityTest <- read.table("UCI HAR Dataset/test/y_test.txt", header = FALSE)
featuresTest <- read.table("UCI HAR Dataset/test/X_test.txt", header = FALSE)
```

### Step 1: Merge the training and the test sets to create one data set

We can use combine the respective data in training and test data sets corresponding to subject, activity and features. The results are stored in `subject`, `activity` and `features`.
```{r}
subject <- rbind(subjectTrain, subjectTest)
activity <- rbind(activityTrain, activityTest)
features <- rbind(featuresTrain, featuresTest)
```

> Naming the columns

The columns in the features data set can be named from the metadata in featureNames
```{r}
colnames(features) <- t(featureNames[2])
```


> Merge the data

The data in `features`, `activity` and `subject` are merged and the complete data is now stored in `completeData`.
```{r}
colnames(activity) <- "Activity"
colnames(subject) <- "Subject"
completeData <- cbind(features,activity,subject)
```


### Step 2: Extracts only the measurements on the mean and standard deviation for each measurement
Extract the column indices that have either mean or std in them.
```{r}
columnsWithMeanSTD <- grep(".*Mean.*|.*Std.*", names(completeData), ignore.case=TRUE)
```

Add activity and subject columns to the list and look at the dimension of `completeData`
```{r}
requiredColumns <- c(columnsWithMeanSTD, 562, 563)
dim(completeData)
```

We create `extractedData` with the selected columns in `requiredColumns`. And again, we look at the dimension of `requiredColumns`.
```{r}
extractedData <- completeData[,requiredColumns]
dim(extractedData)
```


### Step 3: Uses descriptive activity names to name the activities in the data set
The `activity` field in `extractedData` is originally of numeric type. We need to change its type to character so that it can accept activity names. The activity names are taken from metadata `activityLabels`.
```{r}
extractedData$Activity <- as.character(extractedData$Activity)
for (i in 1:6){
extractedData$Activity[extractedData$Activity == i] <- as.character(activityLabels[i,2])
}
```

We need to factor the `activity` variable, once the activity names are updated.
```{r}
extractedData$Activity <- as.factor(extractedData$Activity)
```


### Step 4: Appropriately labels the data set with descriptive variable names
Here are the names of the variables in `extractedData`
```{r}
names(extractedData)
```

* By examining `extractedData`, we can say that the following acronyms can be replaced:
        + `Acc` can be replaced with Accelerometer
        + `Gyro` can be replaced with Gyroscope
        + `BodyBody` can be replaced with Body
        + `Mag` can be replaced with Magnitude
        + Character `f` can be replaced with Frequency
        + Character `t` can be replaced with Time

```{r}
names(extractedData)<-gsub("Acc", "Accelerometer", names(extractedData))
names(extractedData)<-gsub("Gyro", "Gyroscope", names(extractedData))
names(extractedData)<-gsub("BodyBody", "Body", names(extractedData))
names(extractedData)<-gsub("Mag", "Magnitude", names(extractedData))
names(extractedData)<-gsub("^t", "Time", names(extractedData))
names(extractedData)<-gsub("^f", "Frequency", names(extractedData))
names(extractedData)<-gsub("tBody", "TimeBody", names(extractedData))
names(extractedData)<-gsub("-mean()", "Mean", names(extractedData), ignore.case = TRUE)
names(extractedData)<-gsub("-std()", "STD", names(extractedData), ignore.case = TRUE)
names(extractedData)<-gsub("-freq()", "Frequency", names(extractedData), ignore.case = TRUE)
names(extractedData)<-gsub("angle", "Angle", names(extractedData))
names(extractedData)<-gsub("gravity", "Gravity", names(extractedData))
```


Here are the names of the variables in `extractedData` after they are edited
```{r}
names(extractedData)
```


### Step 5:  From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject

Firstly, let us set `Subject` as a factor variable.
```{r}
extractedData$Subject <- as.factor(extractedData$Subject)
extractedData <- data.table(extractedData)
```

We create `tidyData` as a data set with average for each activity and subject. Then, we order the enties in tidyData and write it into data file `Tidy.txt` that contains the processed data.

```{r}
tidyData <- aggregate(. ~Subject + Activity, extractedData, mean)
tidyData <- tidyData[order(tidyData$Subject,tidyData$Activity),]
write.table(tidyData, file = "Tidy.txt", row.names = FALSE)
```
